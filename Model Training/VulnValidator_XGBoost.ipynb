{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e5ccc6-09d5-43b0-b374-663f21bf1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rita/Documents/9309_ML/Smart_Contract_Vulnerabilities_Project/Model Training\n",
      "Training on device: mps\n",
      "X_train shape: torch.Size([4294, 768])\n",
      "y_train shape: torch.Size([4294, 9])\n",
      "X_test shape: torch.Size([1074, 768])\n",
      "y_test shape: torch.Size([1074, 9])\n",
      "screener_train_prob: torch.Size([4294, 1])\n",
      "screener_test_prob: torch.Size([1074, 1])\n",
      "analyzer_train_prob: torch.Size([4294, 9])\n",
      "analyzer_test_prob: torch.Size([1074, 9])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, precision_score, f1_score, recall_score\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# Check for MPS availability (Apple Silicon GPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "X_train = torch.load(\"../codebert/X_train.pt\", weights_only=False).to(device)\n",
    "X_test = torch.load(\"../codebert/X_test.pt\", weights_only=False).to(device)\n",
    "y_train = torch.load(\"../codebert/y_train.pt\", weights_only=False).to(device)\n",
    "y_test = torch.load(\"../codebert/y_test.pt\", weights_only=False).to(device)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Load VulnScreener and get probabilities\n",
    "class VulnScreener(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VulnScreener, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, 256),  # Input layer to Hidden Layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),  # Hidden Layer 1 to Hidden Layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),    # Hidden Layer 2 to Output Layer\n",
    "            nn.Sigmoid()          # Probability output\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)  # Forward pass through the network\n",
    "\n",
    "class VulnAnalyzer(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(VulnAnalyzer, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 769 -> 384\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 384 -> 192\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 192 -> 96\n",
    "        )\n",
    "        # Adjust residual path to match output size of conv3 (256 channels, 96 length)\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv1d(1, 256, kernel_size=1),\n",
    "            nn.AvgPool1d(kernel_size=8, stride=8)  # Downsample 769 to ~96\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256 * 96, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 9),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, p_s):\n",
    "        if p_s.dim() == 1:\n",
    "            p_s = p_s.unsqueeze(1)\n",
    "        x = torch.cat((x, p_s), dim=1).unsqueeze(1)  # [batch_size, 1, 769]\n",
    "        residual = self.residual(x)  # [batch_size, 256, 96]\n",
    "        x = self.conv1(x)  # [batch_size, 64, 384]\n",
    "        x = self.conv2(x)  # [batch_size, 128, 192]\n",
    "        x = self.conv3(x)  # [batch_size, 256, 96]\n",
    "        # Ensure residual matches x’s size\n",
    "        if residual.size(2) != x.size(2):\n",
    "            residual = nn.functional.interpolate(residual, size=x.size(2), mode='nearest')\n",
    "        x = x + residual  # Residual connection\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 256 * 96]\n",
    "        x = self.fc_layers(x)\n",
    "        return x, None\n",
    "\n",
    "screener = VulnScreener().to(device)\n",
    "analyzer = VulnAnalyzer().to(device)\n",
    "\n",
    "screener = torch.load('../codebert/vuln_screener_model.pth', weights_only=False).to(device)\n",
    "analyzer = torch.load('../codebert/vuln_analyzer_model.pth', weights_only=False).to(device)\n",
    "screener.eval()\n",
    "analyzer.eval()\n",
    "\n",
    "# 串接流程\n",
    "with torch.no_grad():\n",
    "    screener_train_prob = screener(X_train).to(device)\n",
    "    screener_test_prob = screener(X_test).to(device)\n",
    "    analyzer_train_prob,_ = analyzer(X_train, screener_train_prob)\n",
    "    analyzer_test_prob,_ = analyzer(X_test, screener_test_prob)\n",
    "    print(f\"screener_train_prob: {screener_train_prob.shape}\") \n",
    "    print(f\"screener_test_prob: {screener_test_prob.shape}\")\n",
    "    print(f\"analyzer_train_prob: {analyzer_train_prob.shape}\")\n",
    "    print(f\"analyzer_test_prob: {analyzer_test_prob.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad4f652-a388-4695-a961-716b54bc992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VulnValidator:\n",
    "    def __init__(self, n_classes=9, random_state=42):\n",
    "        self.n_classes = n_classes\n",
    "        self.random_state = random_state\n",
    "        # 優化 XGBoost 參數\n",
    "        self.model = MultiOutputClassifier(XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            random_state=self.random_state,\n",
    "            max_depth=6,           # 增加樹深度\n",
    "            learning_rate=0.1,     # 降低學習率\n",
    "            n_estimators=200,      # 增加樹數量\n",
    "            scale_pos_weight=5     # 增加正樣本權重，應對不平衡\n",
    "        ))\n",
    "        self.thresholds = None\n",
    "\n",
    "    def _concatenate_features(self, X, analyzer_prob, screener_prob):\n",
    "        X_np = X.cpu().numpy().reshape(X.shape[0], -1)\n",
    "        analyzer_np = analyzer_prob.cpu().numpy().reshape(analyzer_prob.shape[0], -1)\n",
    "        screener_np = screener_prob.cpu().numpy().reshape(screener_prob.shape[0], -1)\n",
    "        return np.concatenate([X_np, analyzer_np, screener_np], axis=1)\n",
    "\n",
    "    def balance_data_per_class(self, X, y, min_samples=500):\n",
    "        \"\"\"\n",
    "        逐類應用 SMOTE，並設置最小樣本數\n",
    "        \"\"\"\n",
    "        smote = SMOTE(random_state=self.random_state, k_neighbors=5)\n",
    "        X_balanced_list = []\n",
    "        y_balanced_list = []\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            y_class = y[:, i]\n",
    "            if y_class.sum() < 5:  # 如果正樣本太少，跳過 SMOTE\n",
    "                X_balanced_list.append(X)\n",
    "                y_balanced_list.append(y_class)\n",
    "                continue\n",
    "            X_bal, y_bal = smote.fit_resample(X, y_class)\n",
    "            X_balanced_list.append(X_bal)\n",
    "            y_balanced_list.append(y_bal)\n",
    "\n",
    "        max_samples = max(max(X.shape[0], min_samples) for X in X_balanced_list)\n",
    "        X_balanced_final = np.zeros((max_samples, X_balanced_list[0].shape[1]))\n",
    "        y_balanced_final = np.zeros((max_samples, self.n_classes))\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            X_bal = X_balanced_list[i]\n",
    "            y_bal = y_balanced_list[i]\n",
    "            indices = np.random.choice(X_bal.shape[0], max_samples, replace=True)\n",
    "            X_balanced_final = X_bal[indices] if i == 0 else X_balanced_final\n",
    "            y_balanced_final[:, i] = y_bal[indices]\n",
    "\n",
    "        return X_balanced_final, y_balanced_final\n",
    "\n",
    "    def fit(self, X_train, analyzer_train_prob, screener_train_prob, y_train):\n",
    "        X_combined = self._concatenate_features(X_train, analyzer_train_prob, screener_train_prob)\n",
    "        y_train_np = y_train.cpu().numpy()\n",
    "\n",
    "        X_balanced, y_balanced = self.balance_data_per_class(X_combined, y_train_np)\n",
    "        print(f\"Balanced X shape: {X_balanced.shape}, Balanced y shape: {y_balanced.shape}\")\n",
    "\n",
    "        self.model.fit(X_balanced, y_balanced)\n",
    "        print(\"XGBoost model training completed.\")\n",
    "\n",
    "    def predict_proba(self, X, analyzer_prob, screener_prob):\n",
    "        X_combined = self._concatenate_features(X, analyzer_prob, screener_prob)\n",
    "        return self.model.predict_proba(X_combined)\n",
    "\n",
    "    def optimize_thresholds(self, X_val, analyzer_val_prob, screener_val_prob, y_val, \n",
    "                          threshold_range=np.arange(0.1, 0.9, 0.05)):\n",
    "        val_probs = self.predict_proba(X_val, analyzer_val_prob, screener_val_prob)\n",
    "        y_val_np = y_val.cpu().numpy()\n",
    "        self.thresholds = np.zeros(self.n_classes)\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            best_f1 = 0\n",
    "            best_threshold = 0.5\n",
    "            y_true = y_val_np[:, i]\n",
    "            y_prob = val_probs[i][:, 1]\n",
    "\n",
    "            for threshold in threshold_range:\n",
    "                y_pred = (y_prob >= threshold).astype(int)\n",
    "                f1 = f1_score(y_true, y_pred)\n",
    "                recall = recall_score(y_true, y_pred)\n",
    "                if f1 > best_f1 and recall > 0.1:  # 提高 Recall 下限\n",
    "                    best_f1 = f1\n",
    "                    best_threshold = threshold\n",
    "\n",
    "            self.thresholds[i] = best_threshold\n",
    "            print(f\"Class {i}: Best Threshold = {best_threshold:.2f}, F1-score = {best_f1:.4f}\")\n",
    "\n",
    "        return self.thresholds\n",
    "\n",
    "    def predict(self, X, analyzer_prob, screener_prob, thresholds=None):\n",
    "        if thresholds is None:\n",
    "            thresholds = self.thresholds if self.thresholds is not None else [0.5] * self.n_classes\n",
    "\n",
    "        probs = self.predict_proba(X, analyzer_prob, screener_prob)\n",
    "        y_pred = np.zeros((X.shape[0], self.n_classes))\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            y_pred[:, i] = (probs[i][:, 1] >= thresholds[i]).astype(int)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a8cd3b-849a-47d6-99a0-a0da71b473c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_outputs(p_a, p_v):\n",
    "    p_v = p_v.to(p_a.device)\n",
    "    p_v = p_v.expand(-1, p_a.shape[1])\n",
    "    \n",
    "    p_f = 0.3 * p_a + 0.7 * p_v\n",
    "    \n",
    "    return p_f\n",
    "    \n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    y_true_np = y_true.cpu().numpy()\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "\n",
    "    if y_pred_np.max() <= 1.0 and y_pred_np.min() >= 0.0:  # 假設是概率\n",
    "        y_pred_np = (y_pred_np >= 0.5).astype(int)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_np, y_pred_np))\n",
    "\n",
    "    for i in range(y_true_np.shape[1]):\n",
    "        print(f\"\\nClass {i} Metrics:\")\n",
    "        print(f\"Precision: {precision_score(y_true_np[:, i], y_pred_np[:, i]):.4f}\")\n",
    "        print(f\"Recall: {recall_score(y_true_np[:, i], y_pred_np[:, i]):.4f}\")\n",
    "        print(f\"F1-score: {f1_score(y_true_np[:, i], y_pred_np[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c130aa-eecb-40de-8fef-bd6a01206e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced X shape: (8470, 778), Balanced y shape: (8470, 9)\n",
      "XGBoost model training completed.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       562\n",
      "           1       0.92      0.07      0.13       978\n",
      "           2       1.00      0.02      0.04      1003\n",
      "           3       0.78      0.01      0.03      1005\n",
      "           4       0.83      0.05      0.09      1004\n",
      "           5       0.95      0.10      0.19      1001\n",
      "           6       0.94      0.19      0.32       983\n",
      "           7       0.87      0.05      0.09       979\n",
      "           8       0.93      0.19      0.31       992\n",
      "\n",
      "   micro avg       0.90      0.14      0.24      8507\n",
      "   macro avg       0.90      0.17      0.23      8507\n",
      "weighted avg       0.90      0.14      0.20      8507\n",
      " samples avg       0.89      0.14      0.24      8507\n",
      "\n",
      "\n",
      "Class 0 Metrics:\n",
      "Precision: 0.8703\n",
      "Recall: 0.8719\n",
      "F1-score: 0.8711\n",
      "\n",
      "Class 1 Metrics:\n",
      "Precision: 0.9167\n",
      "Recall: 0.0675\n",
      "F1-score: 0.1257\n",
      "\n",
      "Class 2 Metrics:\n",
      "Precision: 1.0000\n",
      "Recall: 0.0179\n",
      "F1-score: 0.0353\n",
      "\n",
      "Class 3 Metrics:\n",
      "Precision: 0.7778\n",
      "Recall: 0.0139\n",
      "F1-score: 0.0274\n",
      "\n",
      "Class 4 Metrics:\n",
      "Precision: 0.8305\n",
      "Recall: 0.0488\n",
      "F1-score: 0.0922\n",
      "\n",
      "Class 5 Metrics:\n",
      "Precision: 0.9459\n",
      "Recall: 0.1049\n",
      "F1-score: 0.1888\n",
      "\n",
      "Class 6 Metrics:\n",
      "Precision: 0.9360\n",
      "Recall: 0.1933\n",
      "F1-score: 0.3204\n",
      "\n",
      "Class 7 Metrics:\n",
      "Precision: 0.8654\n",
      "Recall: 0.0460\n",
      "F1-score: 0.0873\n",
      "\n",
      "Class 8 Metrics:\n",
      "Precision: 0.9261\n",
      "Recall: 0.1895\n",
      "F1-score: 0.3146\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       563\n",
      "           1       0.07      0.92      0.13        72\n",
      "           2       0.02      1.00      0.04        18\n",
      "           3       0.01      0.78      0.03        18\n",
      "           4       0.05      0.83      0.09        59\n",
      "           5       0.10      0.95      0.19       111\n",
      "           6       0.19      0.94      0.32       203\n",
      "           7       0.05      0.87      0.09        52\n",
      "           8       0.19      0.93      0.31       203\n",
      "\n",
      "   micro avg       0.14      0.90      0.24      1299\n",
      "   macro avg       0.17      0.90      0.23      1299\n",
      "weighted avg       0.45      0.90      0.51      1299\n",
      " samples avg       0.14      0.89      0.24      1299\n",
      "\n",
      "\n",
      "Class 0 Metrics:\n",
      "Precision: 0.8719\n",
      "Recall: 0.8703\n",
      "F1-score: 0.8711\n",
      "\n",
      "Class 1 Metrics:\n",
      "Precision: 0.0675\n",
      "Recall: 0.9167\n",
      "F1-score: 0.1257\n",
      "\n",
      "Class 2 Metrics:\n",
      "Precision: 0.0179\n",
      "Recall: 1.0000\n",
      "F1-score: 0.0353\n",
      "\n",
      "Class 3 Metrics:\n",
      "Precision: 0.0139\n",
      "Recall: 0.7778\n",
      "F1-score: 0.0274\n",
      "\n",
      "Class 4 Metrics:\n",
      "Precision: 0.0488\n",
      "Recall: 0.8305\n",
      "F1-score: 0.0922\n",
      "\n",
      "Class 5 Metrics:\n",
      "Precision: 0.1049\n",
      "Recall: 0.9459\n",
      "F1-score: 0.1888\n",
      "\n",
      "Class 6 Metrics:\n",
      "Precision: 0.1933\n",
      "Recall: 0.9360\n",
      "F1-score: 0.3204\n",
      "\n",
      "Class 7 Metrics:\n",
      "Precision: 0.0460\n",
      "Recall: 0.8654\n",
      "F1-score: 0.0873\n",
      "\n",
      "Class 8 Metrics:\n",
      "Precision: 0.1895\n",
      "Recall: 0.9261\n",
      "F1-score: 0.3146\n"
     ]
    }
   ],
   "source": [
    "validator = VulnValidator()\n",
    "validator.fit(X_train, analyzer_train_prob, screener_train_prob, y_train)\n",
    "\n",
    "# Get validator predictions\n",
    "validator_test_prob = torch.from_numpy(validator.predict(X_test, analyzer_test_prob, screener_test_prob))\n",
    "validator_test_prob = validator_test_prob.clone().detach().to(device, dtype=torch.float32)\n",
    "evaluate_predictions(validator_test_prob, y_test)\n",
    "\n",
    "# Fuse outputs\n",
    "fuse_test = fuse_outputs(analyzer_test_prob, validator_test_prob)\n",
    "evaluate_predictions(y_test, fuse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09cd56-a150-448d-a5db-b03cd291cc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
