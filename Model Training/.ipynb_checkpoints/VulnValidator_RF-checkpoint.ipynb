{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925919eb-c179-4181-8c16-6ea56137aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rita/Documents/9309_ML/Smart_Contract_Vulnerabilities_Project/Model Training\n",
      "Training on device: mps\n",
      "X_train shape: torch.Size([4294, 768])\n",
      "y_train shape: torch.Size([4294, 9])\n",
      "X_test shape: torch.Size([1074, 768])\n",
      "y_test shape: torch.Size([1074, 9])\n",
      "screener_train_prob: torch.Size([4294, 1])\n",
      "screener_test_prob: torch.Size([1074, 1])\n",
      "analyzer_train_prob: torch.Size([4294, 9])\n",
      "analyzer_test_prob: torch.Size([1074, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# 轉換 X_train / X_test 為 NumPy 並與 Screener 預測機率拼接\\nX_train_np = X_train.cpu().numpy()\\nX_test_np = X_test.cpu().numpy()\\n\\nX_train_combined = np.hstack([X_train_np, screener_train_prob.cpu()])\\nX_test_combined = np.hstack([X_test_np, screener_test_prob.cpu()])\\n\\n# XGBoost 進行預測\\ny_pred_train = analyzer.predict(X_train_combined)\\ny_pred_test = analyzer.predict(X_test_combined)\\n\\n# 取得機率\\nanalyzer_train_prob = np.array([est.predict_proba(X_train_combined)[:, 1] for est in analyzer.estimators_]).T\\nanalyzer_test_prob = np.array([est.predict_proba(X_test_combined)[:, 1] for est in analyzer.estimators_]).T'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import joblib\n",
    "import ast\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, precision_score, f1_score, recall_score\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# Check for MPS availability (Apple Silicon GPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "X_train = torch.load(\"../codebert/X_train.pt\", weights_only=False).to(device)\n",
    "X_test = torch.load(\"../codebert/X_test.pt\", weights_only=False).to(device)\n",
    "y_train = torch.load(\"../codebert/y_train.pt\", weights_only=False).to(device)\n",
    "y_test = torch.load(\"../codebert/y_test.pt\", weights_only=False).to(device)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Load VulnScreener and get probabilities\n",
    "class VulnScreener(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VulnScreener, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, 256),  # Input layer to Hidden Layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),  # Hidden Layer 1 to Hidden Layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),    # Hidden Layer 2 to Output Layer\n",
    "            nn.Sigmoid()          # Probability output\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)  # Forward pass through the network\n",
    "\n",
    "class VulnAnalyzer(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(VulnAnalyzer, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 769 -> 384\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 384 -> 192\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 192 -> 96\n",
    "        )\n",
    "        # Adjust residual path to match output size of conv3 (256 channels, 96 length)\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv1d(1, 256, kernel_size=1),\n",
    "            nn.AvgPool1d(kernel_size=8, stride=8)  # Downsample 769 to ~96\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256 * 96, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 9),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, p_s):\n",
    "        if p_s.dim() == 1:\n",
    "            p_s = p_s.unsqueeze(1)\n",
    "        x = torch.cat((x, p_s), dim=1).unsqueeze(1)  # [batch_size, 1, 769]\n",
    "        residual = self.residual(x)  # [batch_size, 256, 96]\n",
    "        x = self.conv1(x)  # [batch_size, 64, 384]\n",
    "        x = self.conv2(x)  # [batch_size, 128, 192]\n",
    "        x = self.conv3(x)  # [batch_size, 256, 96]\n",
    "        # Ensure residual matches x’s size\n",
    "        if residual.size(2) != x.size(2):\n",
    "            residual = nn.functional.interpolate(residual, size=x.size(2), mode='nearest')\n",
    "        x = x + residual  # Residual connection\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 256 * 96]\n",
    "        x = self.fc_layers(x)\n",
    "        return x, None\n",
    "\n",
    "screener = VulnScreener().to(device)\n",
    "#analyzer = VulnAnalyzer().to(device)\n",
    "\n",
    "screener = torch.load('../codebert/vuln_screener_model.pth', weights_only=False).to(device)\n",
    "#analyzer = joblib.load('../codebert/vuln_analyzer_XGB_model.pkl')\n",
    "analyzer = torch.load('../codebert/vuln_analyzer_model.pth', weights_only=False).to(device)\n",
    "\n",
    "# 載入最佳 Thresholds\n",
    "#with open(\"../codebert/optimal_thresholds.json\", \"r\") as f:\n",
    "#    optimal_thresholds = json.load(f)\n",
    "\n",
    "# 確保 Thresholds 為 NumPy 陣列\n",
    "#thresholds = np.array(list(optimal_thresholds.values()))\n",
    "\n",
    "\n",
    "screener.eval()\n",
    "analyzer.eval()\n",
    "\n",
    "# 串接流程\n",
    "with torch.no_grad():\n",
    "    screener_train_prob = screener(X_train).to(device)\n",
    "    screener_test_prob = screener(X_test).to(device)\n",
    "    analyzer_train_prob,_ = analyzer(X_train, screener_train_prob)\n",
    "    analyzer_test_prob,_ = analyzer(X_test, screener_test_prob)\n",
    "    print(f\"screener_train_prob: {screener_train_prob.shape}\") \n",
    "    print(f\"screener_test_prob: {screener_test_prob.shape}\")\n",
    "    print(f\"analyzer_train_prob: {analyzer_train_prob.shape}\")\n",
    "    print(f\"analyzer_test_prob: {analyzer_test_prob.shape}\")\n",
    "\n",
    "'''# 轉換 X_train / X_test 為 NumPy 並與 Screener 預測機率拼接\n",
    "X_train_np = X_train.cpu().numpy()\n",
    "X_test_np = X_test.cpu().numpy()\n",
    "\n",
    "X_train_combined = np.hstack([X_train_np, screener_train_prob.cpu()])\n",
    "X_test_combined = np.hstack([X_test_np, screener_test_prob.cpu()])\n",
    "\n",
    "# XGBoost 進行預測\n",
    "y_pred_train = analyzer.predict(X_train_combined)\n",
    "y_pred_test = analyzer.predict(X_test_combined)\n",
    "\n",
    "# 取得機率\n",
    "analyzer_train_prob = np.array([est.predict_proba(X_train_combined)[:, 1] for est in analyzer.estimators_]).T\n",
    "analyzer_test_prob = np.array([est.predict_proba(X_test_combined)[:, 1] for est in analyzer.estimators_]).T'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c653e35-2c2f-4214-b44a-c689a7dbc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VulnValidator without attention weights\n",
    "class VulnValidator:\n",
    "    def __init__(self, n_trees=500, max_depth=15, pca_components=50):\n",
    "        self.rf = MultiOutputClassifier(\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=n_trees,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced_subsample\"  # Better imbalance handling\n",
    "            )\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=pca_components)\n",
    "        self.feature_importance = None\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def prepare_features(self, X, p_a, p_s):\n",
    "        X = X.cpu().detach().numpy() if torch.is_tensor(X) else X\n",
    "        p_a = p_a.cpu().detach().numpy() if torch.is_tensor(p_a) else p_a\n",
    "        p_s = p_s.cpu().detach().numpy() if torch.is_tensor(p_s) else p_s\n",
    "        \n",
    "        # Use PCA on X to retain more information\n",
    "        X_pca = self.pca.fit_transform(X)\n",
    "        \n",
    "        # Statistical features\n",
    "        stats = np.hstack([\n",
    "            X.mean(axis=1, keepdims=True),\n",
    "            X.var(axis=1, keepdims=True),\n",
    "            X.max(axis=1, keepdims=True),\n",
    "            X.min(axis=1, keepdims=True)\n",
    "        ])\n",
    "        \n",
    "        # Interaction terms\n",
    "        interaction = p_a * p_s\n",
    "        \n",
    "        # Combine features\n",
    "        features = np.hstack([X_pca, p_a, p_s, stats, interaction])\n",
    "        features = self.scaler.fit_transform(features)\n",
    "        return features\n",
    "    \n",
    "    def fit(self, X, p_a, p_s, y_train):\n",
    "        features = self.prepare_features(X, p_a, p_s)\n",
    "        y_train = y_train.cpu().detach().numpy() if torch.is_tensor(y_train) else y_train\n",
    "        \n",
    "        # Fit the model\n",
    "        self.rf.fit(features, y_train)\n",
    "        \n",
    "        # Aggregate feature importances\n",
    "        self.feature_importance = np.mean([est.feature_importances_ for est in self.rf.estimators_], axis=0)\n",
    "        \n",
    "        # Feature names\n",
    "        num_pca = self.pca.n_components\n",
    "        num_p_a = p_a.shape[1]\n",
    "        num_p_s = p_s.shape[1]\n",
    "        self.feature_names = (\n",
    "            [f\"PCA_{i}\" for i in range(num_pca)] +\n",
    "            [f\"Analyzer_Prob_{i}\" for i in range(num_p_a)] +\n",
    "            [f\"Screener_Prob_{i}\" for i in range(num_p_s)] +\n",
    "            [\"Mean\", \"Variance\", \"Max\", \"Min\"] +\n",
    "            [f\"Interaction_{i}\" for i in range(num_p_a)]\n",
    "        )\n",
    "    \n",
    "    def predict(self, X, p_a, p_s):\n",
    "        features = self.prepare_features(X, p_a, p_s)\n",
    "        p_v = self.rf.predict_proba(features)  # List of [n_samples, 2] arrays\n",
    "        p_v = np.stack([prob[:, 1] for prob in p_v], axis=1)  # [n_samples, 9]\n",
    "        return p_v\n",
    "    \n",
    "    def generate_validation_report(self, p_f, p_v, threshold=0.05, per_sample=False):\n",
    "        report = {\"anomalies\": [], \"corrections\": [], \"top_features\": {}}\n",
    "        if per_sample:\n",
    "            report = {i: {\"anomalies\": [], \"corrections\": [], \"top_features\": {}} for i in range(p_f.shape[0])}\n",
    "    \n",
    "        p_f = p_f.cpu().detach().numpy() if torch.is_tensor(p_f) else p_f\n",
    "        p_v = p_v.cpu().detach().numpy() if torch.is_tensor(p_v) else p_v\n",
    "    \n",
    "        # Ensure shapes match\n",
    "        assert p_f.shape == p_v.shape, f\"Shape mismatch: p_f {p_f.shape}, p_v {p_v.shape}\"\n",
    "    \n",
    "        for i in range(p_f.shape[0]):  # Iterate over samples\n",
    "            sample_anomalies = []\n",
    "            sample_corrections = []\n",
    "            for j in range(p_f.shape[1]):  # Iterate over vulnerabilities\n",
    "                diff = np.abs(p_f[i, j] - p_v[i, j])\n",
    "                #print(f\"p_f:{p_f[i,j]}\")\n",
    "                #print(f\"p_v:{p_v[i,j]}\")\n",
    "                #print(f\"diff:{diff}\")\n",
    "                if diff > threshold:\n",
    "                    if p_f[i, j] > 0.5 and p_v[i, j] < 0.5:\n",
    "                        sample_anomalies.append(f\"Vuln {j}\")\n",
    "                    elif p_f[i, j] < 0.5 and p_v[i, j] > 0.5:\n",
    "                        sample_corrections.append(f\"Vuln {j}\")\n",
    "        \n",
    "            if per_sample:\n",
    "                report[i][\"anomalies\"] = sample_anomalies\n",
    "                report[i][\"corrections\"] = sample_corrections\n",
    "            else:\n",
    "                report[\"anomalies\"].extend(sample_anomalies)\n",
    "                report[\"corrections\"].extend(sample_corrections)\n",
    "    \n",
    "        # Compute top features from all estimators\n",
    "        if hasattr(self.rf, \"estimators_\"):\n",
    "            # Aggregate feature importances across all classifiers\n",
    "            avg_importances = np.mean([est.feature_importances_ for est in self.rf.estimators_], axis=0)\n",
    "            top_5_idx = np.argsort(avg_importances)[-5:][::-1]\n",
    "            report[\"top_features\"] = {self.feature_names[idx]: float(avg_importances[idx]) for idx in top_5_idx}\n",
    "            if per_sample:\n",
    "                for i in range(p_f.shape[0]):\n",
    "                    report[i][\"top_features\"] = report[\"top_features\"]\n",
    "    \n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc9136a-b957-48d7-8080-4346e23d823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_outputs(p_a, p_v):\n",
    "    p_v = p_v.to(p_a.device)\n",
    "    p_v = p_v.expand(-1, p_a.shape[1])\n",
    "    \n",
    "    p_f = 0.5 * p_a + 0.5 * p_v\n",
    "    \n",
    "    return p_f\n",
    "\n",
    "def evaluate_predictions(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"\n",
    "    評估預測結果，計算整體及各漏洞的 Precision, Recall, F1-score, AUC。\n",
    "\n",
    "    :param y_true: 真實標籤 (numpy array) - (N, num_vulns)\n",
    "    :param y_prob: 預測機率 (numpy array) - (N, num_vulns)\n",
    "    :param threshold: 判定為正類別的閾值，預設為 0.5\n",
    "    \"\"\"\n",
    "    if isinstance(y_prob, torch.Tensor):\n",
    "        y_prob = y_prob.cpu().numpy()  # 轉為 NumPy，確保在 CPU 上運行\n",
    "    \n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()  # 同樣轉換 y_true\n",
    "    \n",
    "    # 轉換為二元標籤\n",
    "    y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "    # 計算 Overall 指標\n",
    "    overall_precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_auc = roc_auc_score(y_true, y_prob, average='macro') if len(set(y_true.flatten())) > 1 else None\n",
    "\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "    print(f\"Overall AUC: {overall_auc:.4f}\\n\")\n",
    "\n",
    "    # 計算各個漏洞的 Precision, Recall, F1-score, AUC\n",
    "    num_vulns = y_true.shape[1]\n",
    "    for i in range(num_vulns):\n",
    "        precision = precision_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        recall = recall_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        f1 = f1_score(y_true[:, i], y_pred[:, i], zero_division=0)\n",
    "        auc = roc_auc_score(y_true[:, i], y_prob[:, i]) if len(set(y_true[:, i])) > 1 else None\n",
    "\n",
    "        print(f\"Vuln {i}: Precision={precision:.4f}, Recall={recall:.4f}, \"\n",
    "              f\"F1-Score={f1:.4f}, AUC={auc:.4f}\")\n",
    "\n",
    "# Validation\n",
    "def evaluate_results(p_f, y_true, analyzer_prob, validator_prob):\n",
    "    p_f = p_f.cpu().numpy()  # Convert to numpy for easier handling\n",
    "    y_true = y_true.cpu().numpy()  # Convert to numpy for comparison\n",
    "    \n",
    "    for i in range(p_f.shape[0]):  # 遍歷每一筆測試資料\n",
    "        print(f\"\\nEvaluating sample {i+1}/{p_f.shape[0]}:\")\n",
    "\n",
    "        # 這裡將單一資料的預測結果轉為二進制（0或1）\n",
    "        y_pred = (p_f[i, ] > 0.5).astype(int)\n",
    "        y_true_sample = y_true[i,]\n",
    "\n",
    "        # Print the evaluation metrics for the current sample\n",
    "        print(f\"Predicted: {y_pred}\")\n",
    "        print(f\"True: {y_true_sample}\")\n",
    "\n",
    "        # 生成和顯示該筆資料的報告\n",
    "        report = validator.generate_validation_report(p_f[i].reshape(1, -1), validator_prob[i].reshape(1, -1))\n",
    "        print(f\"Anomalies(Analyzer) for sample {i}: {report['anomalies']}\")\n",
    "        print(f\"Corrections(Validator) for sample {i}: {report['corrections']}\")\n",
    "\n",
    "        # 顯示該筆資料的前 5 個特徵\n",
    "        print(f\"Top 5 Features for sample {i}: {report['top_features']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a77d6a-8429-484f-8336-b0b972bdac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator initialized. Has estimators_: False\n",
      "Overall Precision: 0.7769\n",
      "Overall Recall: 0.6112\n",
      "Overall F1-Score: 0.6767\n",
      "Overall AUC: 0.8924\n",
      "\n",
      "Vuln 0: Precision=0.8725, Recall=0.8632, F1-Score=0.8679, AUC=0.9048\n",
      "Vuln 1: Precision=0.8276, Recall=0.6667, F1-Score=0.7385, AUC=0.9659\n",
      "Vuln 2: Precision=0.8000, Recall=0.4444, F1-Score=0.5714, AUC=0.8295\n",
      "Vuln 3: Precision=0.8000, Recall=0.4444, F1-Score=0.5714, AUC=0.8295\n",
      "Vuln 4: Precision=0.7179, Recall=0.4746, F1-Score=0.5714, AUC=0.8999\n",
      "Vuln 5: Precision=0.5946, Recall=0.5946, F1-Score=0.5946, AUC=0.8444\n",
      "Vuln 6: Precision=0.8525, Recall=0.7685, F1-Score=0.8083, AUC=0.9364\n",
      "Vuln 7: Precision=0.6757, Recall=0.4808, F1-Score=0.5618, AUC=0.8818\n",
      "Vuln 8: Precision=0.8516, Recall=0.7635, F1-Score=0.8052, AUC=0.9393\n",
      "Overall Precision: 0.7451\n",
      "Overall Recall: 0.6585\n",
      "Overall F1-Score: 0.6955\n",
      "Overall AUC: 0.9286\n",
      "\n",
      "Vuln 0: Precision=0.8712, Recall=0.8650, F1-Score=0.8681, AUC=0.9234\n",
      "Vuln 1: Precision=0.8305, Recall=0.6806, F1-Score=0.7481, AUC=0.9287\n",
      "Vuln 2: Precision=0.6667, Recall=0.5556, F1-Score=0.6061, AUC=0.9651\n",
      "Vuln 3: Precision=0.7143, Recall=0.5556, F1-Score=0.6250, AUC=0.9724\n",
      "Vuln 4: Precision=0.7500, Recall=0.5085, F1-Score=0.6061, AUC=0.9007\n",
      "Vuln 5: Precision=0.5802, Recall=0.6847, F1-Score=0.6281, AUC=0.9163\n",
      "Vuln 6: Precision=0.8466, Recall=0.7882, F1-Score=0.8163, AUC=0.9279\n",
      "Vuln 7: Precision=0.6047, Recall=0.5000, F1-Score=0.5474, AUC=0.8969\n",
      "Vuln 8: Precision=0.8421, Recall=0.7882, F1-Score=0.8142, AUC=0.9262\n",
      "\n",
      "Evaluating sample 1/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 0: []\n",
      "Corrections(Validator) for sample 0: []\n",
      "Top 5 Features for sample 0: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 2/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 1: []\n",
      "Corrections(Validator) for sample 1: []\n",
      "Top 5 Features for sample 1: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 3/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 2: []\n",
      "Corrections(Validator) for sample 2: []\n",
      "Top 5 Features for sample 2: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 4/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 3: []\n",
      "Corrections(Validator) for sample 3: []\n",
      "Top 5 Features for sample 3: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 5/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 4: []\n",
      "Corrections(Validator) for sample 4: []\n",
      "Top 5 Features for sample 4: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 6/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 5: []\n",
      "Corrections(Validator) for sample 5: []\n",
      "Top 5 Features for sample 5: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 7/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 6: []\n",
      "Corrections(Validator) for sample 6: []\n",
      "Top 5 Features for sample 6: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 8/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 7: []\n",
      "Corrections(Validator) for sample 7: []\n",
      "Top 5 Features for sample 7: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 9/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 8: []\n",
      "Corrections(Validator) for sample 8: []\n",
      "Top 5 Features for sample 8: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 10/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 9: []\n",
      "Corrections(Validator) for sample 9: []\n",
      "Top 5 Features for sample 9: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 11/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 10: []\n",
      "Corrections(Validator) for sample 10: []\n",
      "Top 5 Features for sample 10: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 12/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 11: []\n",
      "Corrections(Validator) for sample 11: []\n",
      "Top 5 Features for sample 11: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 13/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 12: []\n",
      "Corrections(Validator) for sample 12: []\n",
      "Top 5 Features for sample 12: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 14/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 13: []\n",
      "Corrections(Validator) for sample 13: []\n",
      "Top 5 Features for sample 13: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 15/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 14: []\n",
      "Corrections(Validator) for sample 14: []\n",
      "Top 5 Features for sample 14: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 16/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 15: ['Vuln 1']\n",
      "Corrections(Validator) for sample 15: []\n",
      "Top 5 Features for sample 15: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 17/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 16: []\n",
      "Corrections(Validator) for sample 16: []\n",
      "Top 5 Features for sample 16: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 18/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 17: []\n",
      "Corrections(Validator) for sample 17: []\n",
      "Top 5 Features for sample 17: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 19/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 18: []\n",
      "Corrections(Validator) for sample 18: []\n",
      "Top 5 Features for sample 18: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 20/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 19: []\n",
      "Corrections(Validator) for sample 19: []\n",
      "Top 5 Features for sample 19: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 21/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 20: []\n",
      "Corrections(Validator) for sample 20: []\n",
      "Top 5 Features for sample 20: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 22/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 21: []\n",
      "Corrections(Validator) for sample 21: []\n",
      "Top 5 Features for sample 21: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 23/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 22: []\n",
      "Corrections(Validator) for sample 22: []\n",
      "Top 5 Features for sample 22: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 24/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 23: []\n",
      "Corrections(Validator) for sample 23: []\n",
      "Top 5 Features for sample 23: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 25/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 24: []\n",
      "Corrections(Validator) for sample 24: []\n",
      "Top 5 Features for sample 24: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 26/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 25: []\n",
      "Corrections(Validator) for sample 25: ['Vuln 4']\n",
      "Top 5 Features for sample 25: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 27/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 26: []\n",
      "Corrections(Validator) for sample 26: []\n",
      "Top 5 Features for sample 26: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 28/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 27: []\n",
      "Corrections(Validator) for sample 27: []\n",
      "Top 5 Features for sample 27: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 29/1074:\n",
      "Predicted: [1 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 28: ['Vuln 5']\n",
      "Corrections(Validator) for sample 28: []\n",
      "Top 5 Features for sample 28: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 30/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 29: []\n",
      "Corrections(Validator) for sample 29: []\n",
      "Top 5 Features for sample 29: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 31/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 30: []\n",
      "Corrections(Validator) for sample 30: []\n",
      "Top 5 Features for sample 30: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 32/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 31: []\n",
      "Corrections(Validator) for sample 31: []\n",
      "Top 5 Features for sample 31: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 33/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 32: []\n",
      "Corrections(Validator) for sample 32: []\n",
      "Top 5 Features for sample 32: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 34/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 33: []\n",
      "Corrections(Validator) for sample 33: []\n",
      "Top 5 Features for sample 33: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 35/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 34: []\n",
      "Corrections(Validator) for sample 34: []\n",
      "Top 5 Features for sample 34: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 36/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 35: []\n",
      "Corrections(Validator) for sample 35: []\n",
      "Top 5 Features for sample 35: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 37/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 36: []\n",
      "Corrections(Validator) for sample 36: []\n",
      "Top 5 Features for sample 36: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 38/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 37: []\n",
      "Corrections(Validator) for sample 37: []\n",
      "Top 5 Features for sample 37: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 39/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 38: []\n",
      "Corrections(Validator) for sample 38: []\n",
      "Top 5 Features for sample 38: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 40/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 39: []\n",
      "Corrections(Validator) for sample 39: []\n",
      "Top 5 Features for sample 39: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 41/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 40: []\n",
      "Corrections(Validator) for sample 40: []\n",
      "Top 5 Features for sample 40: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 42/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 41: []\n",
      "Corrections(Validator) for sample 41: []\n",
      "Top 5 Features for sample 41: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 43/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 42: []\n",
      "Corrections(Validator) for sample 42: []\n",
      "Top 5 Features for sample 42: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 44/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 43: []\n",
      "Corrections(Validator) for sample 43: []\n",
      "Top 5 Features for sample 43: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 45/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 44: []\n",
      "Corrections(Validator) for sample 44: []\n",
      "Top 5 Features for sample 44: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 46/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 45: []\n",
      "Corrections(Validator) for sample 45: []\n",
      "Top 5 Features for sample 45: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 47/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 46: []\n",
      "Corrections(Validator) for sample 46: []\n",
      "Top 5 Features for sample 46: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 48/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 47: []\n",
      "Corrections(Validator) for sample 47: []\n",
      "Top 5 Features for sample 47: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 49/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 48: []\n",
      "Corrections(Validator) for sample 48: []\n",
      "Top 5 Features for sample 48: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 50/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 49: []\n",
      "Corrections(Validator) for sample 49: []\n",
      "Top 5 Features for sample 49: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 51/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 50: []\n",
      "Corrections(Validator) for sample 50: []\n",
      "Top 5 Features for sample 50: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 52/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 51: []\n",
      "Corrections(Validator) for sample 51: []\n",
      "Top 5 Features for sample 51: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 53/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 52: ['Vuln 4']\n",
      "Corrections(Validator) for sample 52: []\n",
      "Top 5 Features for sample 52: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 54/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 53: []\n",
      "Corrections(Validator) for sample 53: []\n",
      "Top 5 Features for sample 53: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 55/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 54: []\n",
      "Corrections(Validator) for sample 54: []\n",
      "Top 5 Features for sample 54: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 56/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 55: []\n",
      "Corrections(Validator) for sample 55: []\n",
      "Top 5 Features for sample 55: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 57/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 56: []\n",
      "Corrections(Validator) for sample 56: []\n",
      "Top 5 Features for sample 56: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 58/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 57: []\n",
      "Corrections(Validator) for sample 57: []\n",
      "Top 5 Features for sample 57: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 59/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 58: []\n",
      "Corrections(Validator) for sample 58: []\n",
      "Top 5 Features for sample 58: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 60/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 59: []\n",
      "Corrections(Validator) for sample 59: []\n",
      "Top 5 Features for sample 59: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 61/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 60: []\n",
      "Corrections(Validator) for sample 60: []\n",
      "Top 5 Features for sample 60: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 62/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 61: []\n",
      "Corrections(Validator) for sample 61: []\n",
      "Top 5 Features for sample 61: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 63/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 62: []\n",
      "Corrections(Validator) for sample 62: []\n",
      "Top 5 Features for sample 62: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 64/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 63: []\n",
      "Corrections(Validator) for sample 63: []\n",
      "Top 5 Features for sample 63: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 65/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 64: []\n",
      "Corrections(Validator) for sample 64: []\n",
      "Top 5 Features for sample 64: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 66/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 65: []\n",
      "Corrections(Validator) for sample 65: []\n",
      "Top 5 Features for sample 65: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 67/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 66: []\n",
      "Corrections(Validator) for sample 66: []\n",
      "Top 5 Features for sample 66: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 68/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 67: []\n",
      "Corrections(Validator) for sample 67: []\n",
      "Top 5 Features for sample 67: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 69/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 68: []\n",
      "Corrections(Validator) for sample 68: []\n",
      "Top 5 Features for sample 68: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 70/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 69: []\n",
      "Corrections(Validator) for sample 69: []\n",
      "Top 5 Features for sample 69: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 71/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 70: []\n",
      "Corrections(Validator) for sample 70: []\n",
      "Top 5 Features for sample 70: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 72/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 71: []\n",
      "Corrections(Validator) for sample 71: []\n",
      "Top 5 Features for sample 71: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 73/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 72: []\n",
      "Corrections(Validator) for sample 72: []\n",
      "Top 5 Features for sample 72: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 74/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 73: []\n",
      "Corrections(Validator) for sample 73: []\n",
      "Top 5 Features for sample 73: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 75/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 74: []\n",
      "Corrections(Validator) for sample 74: []\n",
      "Top 5 Features for sample 74: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 76/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 75: ['Vuln 5']\n",
      "Corrections(Validator) for sample 75: []\n",
      "Top 5 Features for sample 75: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 77/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 76: []\n",
      "Corrections(Validator) for sample 76: []\n",
      "Top 5 Features for sample 76: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 78/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 77: []\n",
      "Corrections(Validator) for sample 77: []\n",
      "Top 5 Features for sample 77: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 79/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 78: []\n",
      "Corrections(Validator) for sample 78: []\n",
      "Top 5 Features for sample 78: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 80/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 79: []\n",
      "Corrections(Validator) for sample 79: []\n",
      "Top 5 Features for sample 79: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 81/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 80: []\n",
      "Corrections(Validator) for sample 80: []\n",
      "Top 5 Features for sample 80: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 82/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 81: []\n",
      "Corrections(Validator) for sample 81: []\n",
      "Top 5 Features for sample 81: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 83/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 82: []\n",
      "Corrections(Validator) for sample 82: []\n",
      "Top 5 Features for sample 82: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 84/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 83: []\n",
      "Corrections(Validator) for sample 83: []\n",
      "Top 5 Features for sample 83: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 85/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 84: []\n",
      "Corrections(Validator) for sample 84: []\n",
      "Top 5 Features for sample 84: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 86/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 85: []\n",
      "Corrections(Validator) for sample 85: []\n",
      "Top 5 Features for sample 85: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 87/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 86: []\n",
      "Corrections(Validator) for sample 86: []\n",
      "Top 5 Features for sample 86: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 88/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 87: []\n",
      "Corrections(Validator) for sample 87: []\n",
      "Top 5 Features for sample 87: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 89/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 88: []\n",
      "Corrections(Validator) for sample 88: []\n",
      "Top 5 Features for sample 88: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 90/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 89: []\n",
      "Corrections(Validator) for sample 89: []\n",
      "Top 5 Features for sample 89: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 91/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 90: []\n",
      "Corrections(Validator) for sample 90: []\n",
      "Top 5 Features for sample 90: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 92/1074:\n",
      "Predicted: [0 0 0 0 1 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 91: []\n",
      "Corrections(Validator) for sample 91: []\n",
      "Top 5 Features for sample 91: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 93/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 92: []\n",
      "Corrections(Validator) for sample 92: []\n",
      "Top 5 Features for sample 92: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 94/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 93: []\n",
      "Corrections(Validator) for sample 93: []\n",
      "Top 5 Features for sample 93: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 95/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 94: []\n",
      "Corrections(Validator) for sample 94: []\n",
      "Top 5 Features for sample 94: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 96/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 95: []\n",
      "Corrections(Validator) for sample 95: []\n",
      "Top 5 Features for sample 95: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 97/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 96: []\n",
      "Corrections(Validator) for sample 96: []\n",
      "Top 5 Features for sample 96: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 98/1074:\n",
      "Predicted: [0 0 0 0 1 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 97: []\n",
      "Corrections(Validator) for sample 97: []\n",
      "Top 5 Features for sample 97: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 99/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 98: []\n",
      "Corrections(Validator) for sample 98: []\n",
      "Top 5 Features for sample 98: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 100/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 99: []\n",
      "Corrections(Validator) for sample 99: []\n",
      "Top 5 Features for sample 99: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 101/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 100: []\n",
      "Corrections(Validator) for sample 100: []\n",
      "Top 5 Features for sample 100: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 102/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 101: []\n",
      "Corrections(Validator) for sample 101: []\n",
      "Top 5 Features for sample 101: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 103/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 102: []\n",
      "Corrections(Validator) for sample 102: []\n",
      "Top 5 Features for sample 102: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 104/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 103: []\n",
      "Corrections(Validator) for sample 103: []\n",
      "Top 5 Features for sample 103: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 105/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 104: []\n",
      "Corrections(Validator) for sample 104: []\n",
      "Top 5 Features for sample 104: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 106/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 105: []\n",
      "Corrections(Validator) for sample 105: []\n",
      "Top 5 Features for sample 105: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 107/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 106: []\n",
      "Corrections(Validator) for sample 106: []\n",
      "Top 5 Features for sample 106: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 108/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 107: []\n",
      "Corrections(Validator) for sample 107: []\n",
      "Top 5 Features for sample 107: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 109/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 108: []\n",
      "Corrections(Validator) for sample 108: []\n",
      "Top 5 Features for sample 108: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 110/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 109: []\n",
      "Corrections(Validator) for sample 109: []\n",
      "Top 5 Features for sample 109: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 111/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 110: []\n",
      "Corrections(Validator) for sample 110: []\n",
      "Top 5 Features for sample 110: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 112/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 111: []\n",
      "Corrections(Validator) for sample 111: []\n",
      "Top 5 Features for sample 111: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 113/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 112: []\n",
      "Corrections(Validator) for sample 112: []\n",
      "Top 5 Features for sample 112: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 114/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 113: []\n",
      "Corrections(Validator) for sample 113: []\n",
      "Top 5 Features for sample 113: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 115/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 114: []\n",
      "Corrections(Validator) for sample 114: []\n",
      "Top 5 Features for sample 114: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 116/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 115: []\n",
      "Corrections(Validator) for sample 115: []\n",
      "Top 5 Features for sample 115: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 117/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 116: []\n",
      "Corrections(Validator) for sample 116: []\n",
      "Top 5 Features for sample 116: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 118/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 117: []\n",
      "Corrections(Validator) for sample 117: []\n",
      "Top 5 Features for sample 117: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 119/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 118: []\n",
      "Corrections(Validator) for sample 118: []\n",
      "Top 5 Features for sample 118: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 120/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 119: []\n",
      "Corrections(Validator) for sample 119: []\n",
      "Top 5 Features for sample 119: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 121/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 120: []\n",
      "Corrections(Validator) for sample 120: []\n",
      "Top 5 Features for sample 120: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 122/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 121: []\n",
      "Corrections(Validator) for sample 121: []\n",
      "Top 5 Features for sample 121: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 123/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 122: []\n",
      "Corrections(Validator) for sample 122: []\n",
      "Top 5 Features for sample 122: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 124/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 123: []\n",
      "Corrections(Validator) for sample 123: []\n",
      "Top 5 Features for sample 123: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 125/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 124: []\n",
      "Corrections(Validator) for sample 124: []\n",
      "Top 5 Features for sample 124: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 126/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 125: []\n",
      "Corrections(Validator) for sample 125: []\n",
      "Top 5 Features for sample 125: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 127/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 126: []\n",
      "Corrections(Validator) for sample 126: []\n",
      "Top 5 Features for sample 126: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 128/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 127: []\n",
      "Corrections(Validator) for sample 127: []\n",
      "Top 5 Features for sample 127: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 129/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 128: []\n",
      "Corrections(Validator) for sample 128: []\n",
      "Top 5 Features for sample 128: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 130/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 129: []\n",
      "Corrections(Validator) for sample 129: []\n",
      "Top 5 Features for sample 129: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 131/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 130: []\n",
      "Corrections(Validator) for sample 130: []\n",
      "Top 5 Features for sample 130: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 132/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 131: []\n",
      "Corrections(Validator) for sample 131: []\n",
      "Top 5 Features for sample 131: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 133/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 132: []\n",
      "Corrections(Validator) for sample 132: []\n",
      "Top 5 Features for sample 132: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 134/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 133: []\n",
      "Corrections(Validator) for sample 133: []\n",
      "Top 5 Features for sample 133: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 135/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 134: []\n",
      "Corrections(Validator) for sample 134: []\n",
      "Top 5 Features for sample 134: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 136/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 135: []\n",
      "Corrections(Validator) for sample 135: []\n",
      "Top 5 Features for sample 135: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 137/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 136: []\n",
      "Corrections(Validator) for sample 136: []\n",
      "Top 5 Features for sample 136: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 138/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 137: []\n",
      "Corrections(Validator) for sample 137: []\n",
      "Top 5 Features for sample 137: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 139/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 138: []\n",
      "Corrections(Validator) for sample 138: []\n",
      "Top 5 Features for sample 138: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 140/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 139: []\n",
      "Corrections(Validator) for sample 139: []\n",
      "Top 5 Features for sample 139: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 141/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 140: []\n",
      "Corrections(Validator) for sample 140: []\n",
      "Top 5 Features for sample 140: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 142/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 141: []\n",
      "Corrections(Validator) for sample 141: []\n",
      "Top 5 Features for sample 141: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 143/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 142: []\n",
      "Corrections(Validator) for sample 142: []\n",
      "Top 5 Features for sample 142: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 144/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 143: []\n",
      "Corrections(Validator) for sample 143: []\n",
      "Top 5 Features for sample 143: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 145/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 144: []\n",
      "Corrections(Validator) for sample 144: []\n",
      "Top 5 Features for sample 144: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 146/1074:\n",
      "Predicted: [1 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 145: []\n",
      "Corrections(Validator) for sample 145: []\n",
      "Top 5 Features for sample 145: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 147/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 146: []\n",
      "Corrections(Validator) for sample 146: []\n",
      "Top 5 Features for sample 146: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 148/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 147: []\n",
      "Corrections(Validator) for sample 147: []\n",
      "Top 5 Features for sample 147: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 149/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 148: ['Vuln 7']\n",
      "Corrections(Validator) for sample 148: []\n",
      "Top 5 Features for sample 148: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 150/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 1 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 149: []\n",
      "Corrections(Validator) for sample 149: []\n",
      "Top 5 Features for sample 149: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 151/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 150: []\n",
      "Corrections(Validator) for sample 150: []\n",
      "Top 5 Features for sample 150: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 152/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 151: []\n",
      "Corrections(Validator) for sample 151: []\n",
      "Top 5 Features for sample 151: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 153/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 152: []\n",
      "Corrections(Validator) for sample 152: []\n",
      "Top 5 Features for sample 152: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 154/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 153: []\n",
      "Corrections(Validator) for sample 153: []\n",
      "Top 5 Features for sample 153: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 155/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 154: []\n",
      "Corrections(Validator) for sample 154: []\n",
      "Top 5 Features for sample 154: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 156/1074:\n",
      "Predicted: [1 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 155: []\n",
      "Corrections(Validator) for sample 155: []\n",
      "Top 5 Features for sample 155: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 157/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 156: []\n",
      "Corrections(Validator) for sample 156: []\n",
      "Top 5 Features for sample 156: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 158/1074:\n",
      "Predicted: [1 0 0 0 0 1 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 157: []\n",
      "Corrections(Validator) for sample 157: []\n",
      "Top 5 Features for sample 157: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 159/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 158: []\n",
      "Corrections(Validator) for sample 158: []\n",
      "Top 5 Features for sample 158: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 160/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 159: []\n",
      "Corrections(Validator) for sample 159: []\n",
      "Top 5 Features for sample 159: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 161/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 160: []\n",
      "Corrections(Validator) for sample 160: []\n",
      "Top 5 Features for sample 160: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 162/1074:\n",
      "Predicted: [0 0 0 0 1 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 161: []\n",
      "Corrections(Validator) for sample 161: []\n",
      "Top 5 Features for sample 161: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 163/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 162: []\n",
      "Corrections(Validator) for sample 162: []\n",
      "Top 5 Features for sample 162: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 164/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 163: []\n",
      "Corrections(Validator) for sample 163: []\n",
      "Top 5 Features for sample 163: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 165/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 164: []\n",
      "Corrections(Validator) for sample 164: []\n",
      "Top 5 Features for sample 164: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 166/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 165: []\n",
      "Corrections(Validator) for sample 165: []\n",
      "Top 5 Features for sample 165: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 167/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 166: []\n",
      "Corrections(Validator) for sample 166: []\n",
      "Top 5 Features for sample 166: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 168/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Anomalies(Analyzer) for sample 167: []\n",
      "Corrections(Validator) for sample 167: []\n",
      "Top 5 Features for sample 167: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 169/1074:\n",
      "Predicted: [0 0 0 0 0 0 1 0 1]\n",
      "True: [0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "Anomalies(Analyzer) for sample 168: []\n",
      "Corrections(Validator) for sample 168: []\n",
      "Top 5 Features for sample 168: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 170/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 169: []\n",
      "Corrections(Validator) for sample 169: []\n",
      "Top 5 Features for sample 169: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 171/1074:\n",
      "Predicted: [0 1 0 0 0 0 0 0 0]\n",
      "True: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 170: []\n",
      "Corrections(Validator) for sample 170: []\n",
      "Top 5 Features for sample 170: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 172/1074:\n",
      "Predicted: [0 0 0 0 0 1 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 171: []\n",
      "Corrections(Validator) for sample 171: []\n",
      "Top 5 Features for sample 171: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 173/1074:\n",
      "Predicted: [0 0 1 1 0 0 0 0 0]\n",
      "True: [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 172: []\n",
      "Corrections(Validator) for sample 172: []\n",
      "Top 5 Features for sample 172: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 174/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 173: []\n",
      "Corrections(Validator) for sample 173: []\n",
      "Top 5 Features for sample 173: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 175/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 1 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 174: []\n",
      "Corrections(Validator) for sample 174: []\n",
      "Top 5 Features for sample 174: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 176/1074:\n",
      "Predicted: [0 0 0 0 0 0 0 0 0]\n",
      "True: [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Anomalies(Analyzer) for sample 175: []\n",
      "Corrections(Validator) for sample 175: []\n",
      "Top 5 Features for sample 175: {'Interaction_3': 0.0710727737689441, 'Interaction_2': 0.06661974597052747, 'Interaction_5': 0.061648269669199326, 'Interaction_1': 0.06124121642478429, 'Analyzer_Prob_8': 0.05686403141562608}\n",
      "\n",
      "Evaluating sample 177/1074:\n",
      "Predicted: [1 0 0 0 0 0 0 0 0]\n",
      "True: [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m fuse_test \u001b[38;5;241m=\u001b[39m fuse_outputs(analyzer_test_prob, validator_test_prob)\n\u001b[1;32m     11\u001b[0m evaluate_predictions(y_test, fuse_test)\n\u001b[0;32m---> 13\u001b[0m evaluate_results(fuse_test, y_test, analyzer_test_prob, validator_test_prob)\n",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m, in \u001b[0;36mevaluate_results\u001b[0;34m(p_f, y_true, analyzer_prob, validator_prob)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_true_sample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 生成和顯示該筆資料的報告\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m report \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mgenerate_validation_report(p_f[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), validator_prob[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnomalies(Analyzer) for sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomalies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrections(Validator) for sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrections\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m, in \u001b[0;36mVulnValidator.generate_validation_report\u001b[0;34m(self, p_f, p_v, threshold, per_sample)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Compute top features from all estimators\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimators_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Aggregate feature importances across all classifiers\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     avg_importances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([est\u001b[38;5;241m.\u001b[39mfeature_importances_ \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrf\u001b[38;5;241m.\u001b[39mestimators_], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    106\u001b[0m     top_5_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(avg_importances)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m     report[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names[idx]: \u001b[38;5;28mfloat\u001b[39m(avg_importances[idx]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top_5_idx}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:675\u001b[0m, in \u001b[0;36mBaseForest.feature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03mThe impurity-based feature importances.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;124;03m    array of zeros.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    673\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 675\u001b[0m all_importances \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[1;32m    676\u001b[0m     delayed(\u001b[38;5;28mgetattr\u001b[39m)(tree, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mnode_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    679\u001b[0m )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_importances:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:688\u001b[0m, in \u001b[0;36mBaseDecisionTree.feature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_importances_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the feature importances.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    The importance of a feature is computed as the (normalized) total\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        (Gini importance).\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mcompute_feature_importances()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1621\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m-> 1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1543\u001b[0m, in \u001b[0;36m_is_fitted\u001b[0;34m(estimator, attributes, all_or_any)\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_is_fitted__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__()\n\u001b[1;32m   1542\u001b[0m fitted_attrs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1543\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1544\u001b[0m ]\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fitted_attrs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validator = VulnValidator()\n",
    "validator.fit(X_train, analyzer_train_prob, screener_train_prob, y_train)\n",
    "\n",
    "# Get validator predictions\n",
    "validator_test_prob = torch.from_numpy(validator.predict(X_test, analyzer_test_prob, screener_test_prob))\n",
    "validator_test_prob = validator_test_prob.clone().detach().to(device, dtype=torch.float32)\n",
    "evaluate_predictions(y_test, validator_test_prob)\n",
    "\n",
    "# Fuse outputs\n",
    "fuse_test = fuse_outputs(analyzer_test_prob, validator_test_prob)\n",
    "evaluate_predictions(y_test, fuse_test)\n",
    "\n",
    "evaluate_results(fuse_test, y_test, analyzer_test_prob, validator_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c4f88-5519-44b8-8528-c6545bbe4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(validator.rf, '../codebert/vuln_validator_model.pkl')\n",
    "joblib.dump(validator.scaler, '../codebert/scaler.pkl')\n",
    "joblib.dump(validator.pca, '../codebert/pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f128bf-b56d-4e9d-aaf5-75bafa696f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
