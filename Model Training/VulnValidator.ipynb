{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925919eb-c179-4181-8c16-6ea56137aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rita/Documents/9309_ML/Smart_Contract_Vulnerabilities_Project/Model Training\n",
      "Training on device: mps\n",
      "X_train shape: torch.Size([4294, 768])\n",
      "y_train shape: torch.Size([4294, 9])\n",
      "X_test shape: torch.Size([1074, 768])\n",
      "y_test shape: torch.Size([1074, 9])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix, precision_score, f1_score, recall_score\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# Check for MPS availability (Apple Silicon GPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "X_train = torch.load(\"../codebert/X_train.pt\", weights_only=False).to(device)\n",
    "X_test = torch.load(\"../codebert/X_test.pt\", weights_only=False).to(device)\n",
    "y_train = torch.load(\"../codebert/y_train.pt\", weights_only=False).to(device)\n",
    "y_test = torch.load(\"../codebert/y_test.pt\", weights_only=False).to(device)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Load VulnScreener and get probabilities\n",
    "class VulnScreener(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VulnScreener, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, 256),  # Input layer to Hidden Layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),  # Hidden Layer 1 to Hidden Layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),    # Hidden Layer 2 to Output Layer\n",
    "            nn.Sigmoid()          # Probability output\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)  # Forward pass through the network\n",
    "\n",
    "class VulnAnalyzer(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(VulnAnalyzer, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 769 -> 384\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 384 -> 192\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)  # 192 -> 96\n",
    "        )\n",
    "        # Adjust residual path to match output size of conv3 (256 channels, 96 length)\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv1d(1, 256, kernel_size=1),\n",
    "            nn.AvgPool1d(kernel_size=8, stride=8)  # Downsample 769 to ~96\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256 * 96, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 9),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, p_s):\n",
    "        if p_s.dim() == 1:\n",
    "            p_s = p_s.unsqueeze(1)\n",
    "        x = torch.cat((x, p_s), dim=1).unsqueeze(1)  # [batch_size, 1, 769]\n",
    "        residual = self.residual(x)  # [batch_size, 256, 96]\n",
    "        x = self.conv1(x)  # [batch_size, 64, 384]\n",
    "        x = self.conv2(x)  # [batch_size, 128, 192]\n",
    "        x = self.conv3(x)  # [batch_size, 256, 96]\n",
    "        # Ensure residual matches x’s size\n",
    "        if residual.size(2) != x.size(2):\n",
    "            residual = nn.functional.interpolate(residual, size=x.size(2), mode='nearest')\n",
    "        x = x + residual  # Residual connection\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 256 * 96]\n",
    "        x = self.fc_layers(x)\n",
    "        return x, None\n",
    "\n",
    "screener = VulnScreener().to(device)\n",
    "analyzer = VulnAnalyzer().to(device)\n",
    "\n",
    "screener = torch.load('../codebert/vuln_screener_model.pth', weights_only=False).to(device)\n",
    "analyzer = torch.load('../codebert/vuln_analyzer_model.pth', weights_only=False).to(device)\n",
    "screener.eval()\n",
    "analyzer.eval()\n",
    "\n",
    "# 串接流程\n",
    "with torch.no_grad():\n",
    "    train_prob = screener(X_train)\n",
    "    test_prob = screener(X_test)\n",
    "    analyzer_train_prob = analyzer(X_train, train_prob)\n",
    "    analyzer_test_prob = analyzer(X_test, test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c653e35-2c2f-4214-b44a-c689a7dbc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VulnValidator without attention weights\n",
    "class VulnValidator:\n",
    "    def __init__(self, n_trees=100, max_depth=10, pca_components=50):\n",
    "        self.rf = RandomForestClassifier(\n",
    "            n_estimators=n_trees, \n",
    "            max_depth=max_depth,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.pca = PCA(n_components=pca_components)\n",
    "        self.feature_importance = None\n",
    "        \n",
    "    def prepare_features(self, X, p_a, p_s):\n",
    "        # Move tensors to CPU and convert to NumPy\n",
    "        X = X.cpu().detach().numpy() if torch.is_tensor(X) else X\n",
    "        p_a = p_a.cpu().detach().numpy() if torch.is_tensor(p_a) else p_a\n",
    "        p_s = p_s.cpu().detach().numpy() if torch.is_tensor(p_s) else p_s\n",
    "        \n",
    "        # Compute stats on NumPy arrays (already on CPU)\n",
    "        stats = np.hstack([X.mean(axis=1, keepdims=True), \n",
    "                          X.var(axis=1, keepdims=True)])\n",
    "        features = np.hstack([p_a, p_s, stats])\n",
    "        return features\n",
    "    \n",
    "    def fit(self, X, p_a, p_s, y_train):\n",
    "        features = self.prepare_features(X, p_a, p_s)\n",
    "        y_train = y_train.cpu().detach().numpy() if torch.is_tensor(y_train) else y_train\n",
    "        self.rf.fit(features, y_train)\n",
    "        self.feature_importance = self.rf.feature_importances_\n",
    "    \n",
    "    def predict(self, X, p_a, p_s):\n",
    "        features = self.prepare_features(X, p_a, p_s)\n",
    "        p_v = self.rf.predict_proba(features)[:, 1]  # Adjust if multi-label\n",
    "        return p_v\n",
    "    \n",
    "    def generate_validation_report(self, p_a, p_v, threshold=0.2):\n",
    "        report = {\"anomalies\": [], \"corrections\": []}\n",
    "        p_a = p_a.cpu().detach().numpy() if torch.is_tensor(p_a) else p_a\n",
    "        \n",
    "        for i in range(p_a.shape[1]):\n",
    "            diff = np.abs(p_a[:, i] - p_v[:, i])\n",
    "            mask_anomaly = (diff > threshold) & (p_a[:, i] > 0.5) & (p_v[:, i] < 0.5)\n",
    "            mask_correction = (diff > threshold) & (p_a[:, i] < 0.5) & (p_v[:, i] > 0.5)\n",
    "            \n",
    "            if np.any(mask_anomaly):\n",
    "                report[\"anomalies\"].append(f\"Vuln {i}\")\n",
    "            if np.any(mask_correction):\n",
    "                report[\"corrections\"].append(f\"Vuln {i}\")\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc9136a-b957-48d7-8080-4346e23d823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_outputs(p_a, p_v):\n",
    "    p_f = 0.7 * p_a + 0.3 * p_v\n",
    "    p_f0 = (p_f.max(dim=1)[0] > 0.5).float().unsqueeze(1)\n",
    "    return torch.cat([p_f0, p_f], dim=1)\n",
    "\n",
    "# Validation\n",
    "def evaluate_results(p_f, y_true, split=\"Test\"):\n",
    "    y_pred = (p_f[:, 1:] > 0.5).float().cpu().numpy()\n",
    "    y_true = y_true[:, 1:].cpu().numpy()\n",
    "    \n",
    "    print(f\"\\n{split} Set Results:\")\n",
    "    accuracy_per_vuln = [accuracy_score(y_true[:, i], y_pred[:, i]) for i in range(8)]\n",
    "    for i, acc in enumerate(accuracy_per_vuln):\n",
    "        print(f\"Vuln {i}: Accuracy = {acc:.4f}\")\n",
    "    print(f\"Overall Accuracy: {accuracy_score(y_true.flatten(), y_pred.flatten()):.4f}\")\n",
    "    \n",
    "    # Generate and print validation report\n",
    "    report = validator.generate_validation_report(analyzer_test_prob if split == \"Test\" else analyzer_train_prob, \n",
    "                                                p_v_test if split == \"Test\" else p_v_train)\n",
    "    print(f\"\\nValidation Report ({split}):\")\n",
    "    print(f\"Anomalies: {report['anomalies']}\")\n",
    "    print(f\"Corrections: {report['corrections']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca8ebe24-4fb7-46f3-8c20-8f5740ae18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train device: mps:0\n",
      "train_prob device: mps:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#print(f\"analyzer_train_prob device: {analyzer_train_prob.device}\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m validator \u001b[38;5;241m=\u001b[39m VulnValidator()\n\u001b[0;32m----> 6\u001b[0m validator\u001b[38;5;241m.\u001b[39mfit(X_train, analyzer_train_prob, train_prob, y_train)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Get validator predictions\u001b[39;00m\n\u001b[1;32m      9\u001b[0m p_v_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(validator\u001b[38;5;241m.\u001b[39mpredict(X_train, analyzer_train_prob, train_prob))\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mVulnValidator.fit\u001b[0;34m(self, X, p_a, p_s, y_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, p_a, p_s, y_train):\n\u001b[0;32m---> 25\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_features(X, p_a, p_s)\n\u001b[1;32m     26\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(y_train) \u001b[38;5;28;01melse\u001b[39;00m y_train\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrf\u001b[38;5;241m.\u001b[39mfit(features, y_train)\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mVulnValidator.prepare_features\u001b[0;34m(self, X, p_a, p_s)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Compute stats on NumPy arrays (already on CPU)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m stats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[1;32m     20\u001b[0m                   X\u001b[38;5;241m.\u001b[39mvar(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[0;32m---> 21\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([p_a, p_s, stats])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/shape_base.py:352\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_vhstack_dispatcher)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(tup, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    Stack arrays in sequence horizontally (column wise).\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m atleast_1d(\u001b[38;5;241m*\u001b[39mtup)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    354\u001b[0m         arrs \u001b[38;5;241m=\u001b[39m [arrs]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m asanyarray(ary)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(f\"X_train device: {X_train.device}\")\n",
    "print(f\"train_prob device: {train_prob.device}\")\n",
    "#print(f\"analyzer_train_prob device: {analyzer_train_prob.device}\")\n",
    "\n",
    "validator = VulnValidator()\n",
    "validator.fit(X_train, analyzer_train_prob, train_prob, y_train)\n",
    "\n",
    "# Get validator predictions\n",
    "p_v_train = torch.tensor(validator.predict(X_train, analyzer_train_prob, train_prob))\n",
    "p_v_test = torch.tensor(validator.predict(X_test, analyzer_test_prob, test_prob))\n",
    "\n",
    "# Fuse outputs\n",
    "p_f_train = fuse_outputs(analyzer_train_prob, p_v_train)\n",
    "p_f_test = fuse_outputs(analyzer_test_prob, p_v_test)\n",
    "\n",
    "evaluate_results(p_f_train, y_train, \"Train\")\n",
    "evaluate_results(p_f_test, y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a77d6a-8429-484f-8336-b0b972bdac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
